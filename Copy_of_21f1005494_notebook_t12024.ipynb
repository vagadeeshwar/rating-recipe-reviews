{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g7cCcge8pVU3"
      },
      "source": [
        "# Initialization Codes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-04-07T18:48:31.229156Z",
          "iopub.status.busy": "2024-04-07T18:48:31.228729Z",
          "iopub.status.idle": "2024-04-07T18:48:31.662329Z",
          "shell.execute_reply": "2024-04-07T18:48:31.661236Z",
          "shell.execute_reply.started": "2024-04-07T18:48:31.229118Z"
        },
        "id": "58GlbXfsJEBH",
        "outputId": "751825c4-ef93-49a5-999c-39c82f8c690d",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "# import os\n",
        "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "#     for filename in filenames:\n",
        "#         print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-07T18:48:33.852939Z",
          "iopub.status.busy": "2024-04-07T18:48:33.851924Z",
          "iopub.status.idle": "2024-04-07T18:48:34.103053Z",
          "shell.execute_reply": "2024-04-07T18:48:34.102241Z",
          "shell.execute_reply.started": "2024-04-07T18:48:33.852894Z"
        },
        "id": "xkfdiZfmJEBI",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Read the data\n",
        "X_full = pd.read_csv('../input/recipe-for-rating-predict-food-ratings-using-ml/train.csv', index_col='ID')\n",
        "X_test = pd.read_csv('../input/recipe-for-rating-predict-food-ratings-using-ml/test.csv', index_col='ID')\n",
        "\n",
        "y=X_full.Rating\n",
        "X=X_full.drop(\"Rating\",axis=1)\n",
        "\n",
        "# Reconfiguring indexes\n",
        "\n",
        "X1 = X.reset_index(drop=True)\n",
        "y1 = y.reset_index(drop=True)\n",
        "X_test = X_test.reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-07T18:48:34.282374Z",
          "iopub.status.busy": "2024-04-07T18:48:34.281379Z",
          "iopub.status.idle": "2024-04-07T18:48:34.295582Z",
          "shell.execute_reply": "2024-04-07T18:48:34.294487Z",
          "shell.execute_reply.started": "2024-04-07T18:48:34.282328Z"
        },
        "id": "sNDJsfU2wrE1",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Null Value Removal\n",
        "X1.dropna(subset=[\"Recipe_Review\"],inplace=True)\n",
        "y1=y1.iloc[X1.index]\n",
        "\n",
        "X1.reset_index(drop=True,inplace=True)\n",
        "y1.reset_index(drop=True,inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ppv7cNoZJEBJ"
      },
      "source": [
        "# EDA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "43IVn8iMJEBK"
      },
      "outputs": [],
      "source": [
        "X.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SHcUPcdGJEBK"
      },
      "outputs": [],
      "source": [
        "X.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "upkcrWVUJEBL"
      },
      "outputs": [],
      "source": [
        "X.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xaODuD8VJEBL"
      },
      "outputs": [],
      "source": [
        "y.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8DGG1rr-JEBL"
      },
      "outputs": [],
      "source": [
        "X.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "29Lk2vIWJEBM"
      },
      "outputs": [],
      "source": [
        "X.index.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-wyIP8LrJEBM"
      },
      "outputs": [],
      "source": [
        "X.groupby('RecipeNumber')['RecipeCode'].count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pMRMvWUuJEBM"
      },
      "outputs": [],
      "source": [
        "X.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LddUbUu8JEBN"
      },
      "outputs": [],
      "source": [
        "X.UserReputation.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GPgVF-89JEBN"
      },
      "outputs": [],
      "source": [
        "X.ReplyCount.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZdbRgRrJJEBN"
      },
      "outputs": [],
      "source": [
        "X.BestScore.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hqGleeefJEBN"
      },
      "outputs": [],
      "source": [
        "X.hist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NtNVdI0-JEBN"
      },
      "outputs": [],
      "source": [
        "plt.scatter(X.BestScore,y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HwgHUeK9JEBN"
      },
      "source": [
        "* 2 null in Recipe_Review\n",
        "* X has duplicate IDs(index)... Comment ID performs like an index instead\n",
        "* Multiple recipe codes present in same recipe number(ranking 1-100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TXhrGJBQEtCI"
      },
      "source": [
        "# Text Analysis and Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-07T18:48:37.973895Z",
          "iopub.status.busy": "2024-04-07T18:48:37.973513Z",
          "iopub.status.idle": "2024-04-07T18:48:38.001883Z",
          "shell.execute_reply": "2024-04-07T18:48:38.000884Z",
          "shell.execute_reply.started": "2024-04-07T18:48:37.973864Z"
        },
        "id": "qTT2KZ_ikXZu",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "# pattern_presence = pd.DataFrame(index=X.index, columns=patterns.keys())\n",
        "\n",
        "# for pattern_name, pattern in patterns.items():\n",
        "#     pattern_presence[pattern_name] = X.str.contains(pattern).astype(int)\n",
        "\n",
        "# num_dict={col:sum(pattern_presence[col]) for col in pattern_presence.columns}\n",
        "\n",
        "# pattern_presence\n",
        "# num_dict\n",
        "\n",
        "# emoji_counts = X.str.findall(patterns['emoji_pattern']).explode().value_counts()\n",
        "# out_of_ascii_counts = X.str.findall(patterns['out_of_ascii']).explode().value_counts()\n",
        "# emoticons = X.str.findall(patterns['emoticons']).explode().value_counts()\n",
        "# entities = X.str.findall(patterns['html_entities']).explode().value_counts()\n",
        "# # hanging = X.str.findall(patterns['hanging_parantheses']).explode().value_counts()\n",
        "\n",
        "# print(\"Emoji Counts:\")\n",
        "# print(emoji_counts)\n",
        "# print(\"\\nOut of ASCII Counts:\")\n",
        "# print(out_of_ascii_counts)\n",
        "# print(\"\\nEmoticons:\")\n",
        "# print(emoticons)\n",
        "# print(\"\\nEntities:\")\n",
        "# print(entities)\n",
        "# # print(\"\\nHanging Parantheses:\")\n",
        "# # print(hanging)\n",
        "\n",
        "# pattern_presence = pd.DataFrame(index=X.index, columns=patterns.keys())\n",
        "\n",
        "# for pattern_name, pattern in patterns.items():\n",
        "#     pattern_presence[pattern_name] = X.str.contains(pattern).astype(int)\n",
        "\n",
        "# num_dict={col:sum(pattern_presence[col]) for col in pattern_presence.columns}\n",
        "\n",
        "# pattern_presence\n",
        "# num_dict\n",
        "\n",
        "# emoji_counts = X.str.findall(patterns['emoji_pattern']).explode().value_counts()\n",
        "# out_of_ascii_counts = X.str.findall(patterns['out_of_ascii']).explode().value_counts()\n",
        "# emoticons = X.str.findall(patterns['emoticons']).explode().value_counts()\n",
        "# entities = X.str.findall(patterns['html_entities']).explode().value_counts()\n",
        "# # hanging = X.str.findall(patterns['hanging_parantheses']).explode().value_counts()\n",
        "\n",
        "# print(\"Emoji Counts:\")\n",
        "# print(emoji_counts)\n",
        "# print(\"\\nOut of ASCII Counts:\")\n",
        "# print(out_of_ascii_counts)\n",
        "# print(\"\\nEmoticons:\")\n",
        "# print(emoticons)\n",
        "# print(\"\\nEntities:\")\n",
        "# print(entities)\n",
        "# # print(\"\\nHanging Parantheses:\")\n",
        "# # print(hanging)\n",
        "\n",
        "def replace_patterns(X):\n",
        "\n",
        "    patterns = {\n",
        "        'html_entities': r'&[a-zA-Z0-9]+;|&#[a-zA-Z0-9]+;',\n",
        "        'urls': r'https?://\\S+',\n",
        "        'email_addresses': r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b',\n",
        "        'html_tags': r'<.*>|</.*>|<.*>(.*?)</.*>',\n",
        "        'whitespace_pattern': r'\\s\\s+',\n",
        "        'emoji_pattern': r'[\\U0001F600-\\U0001F64F\\U0001F300-\\U0001F5FF\\U0001F680-\\U0001F6FF\\U0001F700-\\U0001F77F\\U0001F780-\\U0001F7FF\\U0001F800-\\U0001F8FF\\U0001F900-\\U0001F9FF\\U0001FA00-\\U0001FA6F\\U0001FA70-\\U0001FAFF\\U00002702-\\U000027B0]+|[\\U0001F1E0-\\U0001F1FF]{2}|\\u200d',\n",
        "        'emoticons': r'(?::|;|=)(?:-)?(?:\\)|\\(|D|P)',\n",
        "        'out_of_ascii': r'[^\\x00-\\x7F]+'\n",
        "    }\n",
        "\n",
        "    replacements = {\n",
        "        \"'\": \"'\",\n",
        "        \"\"\": '\"',\n",
        "        \"\"\": '\"',\n",
        "        \"é\": \"e\",\n",
        "        \"×\": \"x\",\n",
        "        \"ñ\": \"n\",\n",
        "        \"è\": \"e\",\n",
        "        \"â\": \"a\",\n",
        "        \"½\": \"0.5\",\n",
        "        \"¼\": \"0.25\",\n",
        "        \"⅛\": \"0.125\",\n",
        "        \"'\": \"'\",\n",
        "        \"´\": \"'\",\n",
        "        r\"[:;][o0]\\)?\": \" \",\n",
        "        r\"\\.\\.*\": \", \",\n",
        "        r\"!!*\": \"!\",\n",
        "        r\"--*\": \"-\",\n",
        "        r\",,*\": \",\",\n",
        "        r\"^re:\": \"\",\n",
        "        r\"\\?\\?*\": \"?\",\n",
        "        r\"(?<!\\\\)([_\\*~])[\\s\\S]*?\\1\": \"\",\n",
        "        \"&#39;\": \"'\",\n",
        "        \"&amp;\": \"&\",\n",
        "        \"&gt;\": \" \",\n",
        "        \"&lt;\": \" \",\n",
        "        \"&#34;\": '\"'\n",
        "    }\n",
        "\n",
        "    contractions = {\n",
        "        r\"\\bain't\\b\": \"am not\",\n",
        "        r\"\\baren't\\b\": \"are not\",\n",
        "        r\"\\bcan't\\b\": \"can not\",\n",
        "        r\"\\bcouldn't\\b\": \"could not\",\n",
        "        r\"\\bdidn't\\b\": \"did not\",\n",
        "        r\"\\bdoesn't\\b\": \"does not\",\n",
        "        r\"\\bdon't\\b\": \"do not\",\n",
        "        r\"\\bhadn't\\b\": \"had not\",\n",
        "        r\"\\bhasn't\\b\": \"has not\",\n",
        "        r\"\\bhaven't\\b\": \"have not\",\n",
        "        r\"\\bhe'd\\b\": \"he would\",\n",
        "        r\"\\bhe'll\\b\": \"he will\",\n",
        "        r\"\\bhe's\\b\": \"he is\",\n",
        "        r\"\\bi'd\\b\": \"i would\",\n",
        "        r\"\\bi'll\\b\": \"i will\",\n",
        "        r\"\\bi'm\\b\": \"i am\",\n",
        "        r\"\\bi've\\b\": \"i have\",\n",
        "        r\"\\bisn't\\b\": \"is not\",\n",
        "        r\"\\bit's\\b\": \"it is\",\n",
        "        r\"\\blet's\\b\": \"let us\",\n",
        "        r\"\\bma'am\\b\": \"madam\",\n",
        "        r\"\\bmayn't\\b\": \"may not\",\n",
        "        r\"\\bmight've\\b\": \"might have\",\n",
        "        r\"\\bmightn't\\b\": \"might not\",\n",
        "        r\"\\bmust've\\b\": \"must have\",\n",
        "        r\"\\bmustn't\\b\": \"must not\",\n",
        "        r\"\\bshan't\\b\": \"shall not\",\n",
        "        r\"\\bshe'd\\b\": \"she would\",\n",
        "        r\"\\bshe'll\\b\": \"she will\",\n",
        "        r\"\\bshe's\\b\": \"she is\",\n",
        "        r\"\\bshould've\\b\": \"should have\",\n",
        "        r\"\\bshouldn't\\b\": \"should not\",\n",
        "        r\"\\bthat's\\b\": \"that is\",\n",
        "        r\"\\bthere's\\b\": \"there is\",\n",
        "        r\"\\bthey'd\\b\": \"they would\",\n",
        "        r\"\\bthey'll\\b\": \"they will\",\n",
        "        r\"\\bthey're\\b\": \"they are\",\n",
        "        r\"\\bthey've\\b\": \"they have\",\n",
        "        r\"\\bwasn't\\b\": \"was not\",\n",
        "        r\"\\bwe'd\\b\": \"we would\",\n",
        "        r\"\\bwe'll\\b\": \"we will\",\n",
        "        r\"\\bwe're\\b\": \"we are\",\n",
        "        r\"\\bwe've\\b\": \"we have\",\n",
        "        r\"\\bweren't\\b\": \"were not\",\n",
        "        r\"\\bwhat'll\\b\": \"what will\",\n",
        "        r\"\\bwhat're\\b\": \"what are\",\n",
        "        r\"\\bwhat's\\b\": \"what is\",\n",
        "        r\"\\bwhat've\\b\": \"what have\",\n",
        "        r\"\\bwhere's\\b\": \"where is\",\n",
        "        r\"\\bwho'll\\b\": \"who will\",\n",
        "        r\"\\bwho's\\b\": \"who is\",\n",
        "        r\"\\bwon't\\b\": \"will not\",\n",
        "        r\"\\bwould've\\b\": \"would have\",\n",
        "        r\"\\bwouldn't\\b\": \"would not\",\n",
        "        r\"\\byou'd\\b\": \"you would\",\n",
        "        r\"\\byou'll\\b\": \"you will\",\n",
        "        r\"\\byou're\\b\": \"you are\",\n",
        "        r\"\\byou've\\b\": \"you have\"\n",
        "    }\n",
        "\n",
        "    custom_stop_words = {\n",
        "        r\"\\badded\\b\": \"add\",\n",
        "        r\"\\bcups\\b\": \"cup\",\n",
        "        r\"\\bloved\\b\": \"love\",\n",
        "        r\"\\bloves\\b\": \"love\",\n",
        "        r\"\\bliked\\b\": \"like\",\n",
        "        r\"\\brecipes\\b\": \"recipe\",\n",
        "        r\"\\bthanks\\b\": \"thank\",\n",
        "        r\"\\btasty\\b\": \"taste\",\n",
        "        r\"\\bcooked\\b\": \"cook\",\n",
        "        r\"\\badding\\b\": \"add\",\n",
        "        r\"\\bmade\\b\": \"make\",\n",
        "        r\"\\bmaking\\b\": \"make\",\n",
        "        r\"\\bmakes\\b\": \"make\",\n",
        "        r\"\\bthought\\b\": \"think\",\n",
        "        r\"\\btimes\\b\": \"time\",\n",
        "        r\"\\btried\\b\": \"try\",\n",
        "        r\"\\bused\\b\":\"use\",\n",
        "    }\n",
        "\n",
        "    X = X.str.lower()\n",
        "\n",
        "    X = X.str.replace(patterns['emoji_pattern'], \" \", regex=True)\n",
        "    X = X.str.replace(patterns['emoticons'], \" \", regex=True)\n",
        "    X = X.str.replace(patterns['out_of_ascii'], \" \", regex=True)\n",
        "    X = X.str.replace(patterns['html_tags'], \" \", regex=True)\n",
        "    X = X.str.replace(patterns['urls'], \" \", regex=True)\n",
        "    X = X.str.replace(patterns['email_addresses'], \" \", regex=True)\n",
        "\n",
        "    my_punct = ['!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '.',\n",
        "        '/', ':', ';', '<', '=', '>', '?', '@', '[', '\\\\', ']', '^', '_',\n",
        "        '`', '{', '|', '}', '~', '»', '«', '“', '”']\n",
        "\n",
        "\n",
        "    X = X.replace(replacements, regex=True)\n",
        "    X = X.replace(contractions, regex=True)\n",
        "\n",
        "    punct_pattern = re.compile(\"[\" + re.escape(\"\".join(my_punct)) + \"]\")\n",
        "    X=X.apply(lambda x:re.sub(punct_pattern, \"\", x))\n",
        "    X = X.replace(custom_stop_words, regex=True)\n",
        "    with open('../input/dataset/stopwords.txt', 'r') as file:\n",
        "        stopwords = file.read().splitlines()\n",
        "\n",
        "\n",
        "    stopwords_pattern = re.compile(r'\\b(' + r'|'.join(stopwords) + r')\\b\\s*')\n",
        "    X = X.str.replace(stopwords_pattern, '', regex=True)\n",
        "\n",
        "    X = X.str.replace(patterns['whitespace_pattern'], \" \", regex=True)\n",
        "\n",
        "    return X"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oR5W2S1TfyzN"
      },
      "source": [
        "{'html_entities': 5010,\n",
        " 'urls': 26,\n",
        " 'email_addresses': 6,\n",
        " 'html_tags': 81,\n",
        " 'whitespace_pattern': 6291,\n",
        " 'emoji_pattern': 15,\n",
        " 'emoticons': 328,\n",
        " 'out_of_ascii': 594}\n",
        "\n",
        "Emoji Counts:\n",
        "Recipe_Review\n",
        "😋      3\n",
        "❤      2\n",
        "😍      2\n",
        "‍      2\n",
        "😋❤🤗    1\n",
        "🙄🤦🏽    1\n",
        "🥰🥰🥰    1\n",
        "🥰      1\n",
        "🤗      1\n",
        "😅      1\n",
        "😝      1\n",
        "🙄😑     1\n",
        "🤣      1\n",
        "🤦      1\n",
        "Name: count, dtype: int64\n",
        "\n",
        "Out of ASCII Counts:\n",
        "Recipe_Review\n",
        "’          711\n",
        "           156\n",
        "“           79\n",
        "”           76\n",
        "é           42\n",
        "°           16\n",
        "…           12\n",
        "—            7\n",
        "ñ            7\n",
        "             5\n",
        "½            5\n",
        "¼            4\n",
        "‘            4\n",
        "😋            3\n",
        "è            3\n",
        "❤️           2\n",
        "º            2\n",
        "😍            2\n",
        "â            2\n",
        "😅            1\n",
        "😝            1\n",
        "🙄😑           1\n",
        "–            1\n",
        "⅛            1\n",
        "🤣            1\n",
        "🤦‍♀️         1\n",
        "🥰            1\n",
        "🤗            1\n",
        "•            1\n",
        "🥰🥰🥰          1\n",
        "🙄🤦🏽‍♀️       1\n",
        "😋❤🤗          1\n",
        "☺️           1\n",
        "´¯           1\n",
        "¸¸           1\n",
        "             1\n",
        "×            1\n",
        "´            1\n",
        "Name: count, dtype: int64\n",
        "\n",
        "Emoticons:\n",
        "Recipe_Review\n",
        ":)     243\n",
        ":-)     40\n",
        ";)      29\n",
        ":(      19\n",
        "=)       8\n",
        ";-)      7\n",
        "Name: count, dtype: int64\n",
        "\n",
        "Entities:\n",
        "Recipe_Review\n",
        "&#39;    7209\n",
        "&#34;    1342\n",
        "&amp;     775\n",
        "&gt;        8\n",
        "&lt;        7\n",
        "Name: count, dtype: int64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-07T18:48:40.511743Z",
          "iopub.status.busy": "2024-04-07T18:48:40.510895Z",
          "iopub.status.idle": "2024-04-07T18:48:41.046992Z",
          "shell.execute_reply": "2024-04-07T18:48:41.046164Z",
          "shell.execute_reply.started": "2024-04-07T18:48:40.511708Z"
        },
        "id": "8MkR1yrC_T3d",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "from sklearn.base import TransformerMixin, BaseEstimator\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import string\n",
        "\n",
        "# Estimator TfidfTransformer should store all parameters as an attribute during init.\n",
        "#Please remember all these comments when you do another ml project... every one of these took hours to debug!\n",
        "\n",
        "class TfidfTransformer(TransformerMixin, BaseEstimator):\n",
        "    def __init__(self, ngram_range=(1, 1), max_features=100):\n",
        "        self.max_features=max_features\n",
        "        self.ngram_range=ngram_range\n",
        "        self.vectorizer = TfidfVectorizer(stop_words=None, lowercase=False, strip_accents=None, ngram_range=self.ngram_range, max_features=self.max_features)\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        self.vectorizer.fit(X.squeeze())\n",
        "        return self\n",
        "\n",
        "    def transform(self, X, y=None):\n",
        "        return self.vectorizer.transform(X.squeeze())\n",
        "\n",
        "    def get_feature_names_out(self, input_features=None):\n",
        "        print(self.vectorizer.get_feature_names_out())\n",
        "        return self.vectorizer.get_feature_names_out()\n",
        "\n",
        "# Use this to check correctness but don't take it too seriously.. solve error one by one and then again check if custom transformer works\n",
        "\n",
        "# from sklearn.utils.estimator_checks import check_estimator\n",
        "# check_estimator(TfidfTransformer())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-07T18:48:41.736167Z",
          "iopub.status.busy": "2024-04-07T18:48:41.735791Z",
          "iopub.status.idle": "2024-04-07T18:48:54.734214Z",
          "shell.execute_reply": "2024-04-07T18:48:54.73307Z",
          "shell.execute_reply.started": "2024-04-07T18:48:41.736136Z"
        },
        "id": "rC_Evl0wWbK-",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# HAVING REPLACE INSIDE OF PIPELINE AND RUNNING IT EVERYTIME DURING CV IS USELESS AS REPLACE CODE IS FIXED AND IT HAS NOTHING TO LEARN FROM THE INDIVIDUAL CV SPLITS\n",
        "X2=X1.copy(deep=True)\n",
        "X2.Recipe_Review=replace_patterns(X1.Recipe_Review)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CWTHbHohzQ0v"
      },
      "source": [
        "# Pipelines"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rUy35uGVJEBN"
      },
      "source": [
        "<ul>\n",
        "<li>RecipeName: Name of the recipe the comment was posted on -> <b>Dropped</b> </li>\n",
        "<li>CommentID: Unique ID of the comment -> <b>Dropped</b> </li>\n",
        "<li>UserName: Name of the user -> <b>Dropped</b> </li>\n",
        "</ul>\n",
        "\n",
        "<ul>\n",
        "    <li>RecipeNumber: Placement of the recipe on the top 100 recipes list -> <b>Not used</b> </li>\n",
        "<li>RecipeCode: Unique ID of the recipe used by the site -> <b>Not used</b> </li>\n",
        "<li>UserID: Unique ID of the user who left the comment -> <b>Not used</b></li>\n",
        "    <li>CreationTimestamp: Time at which the comment was posted as a Unix timestamp -> <b>Not used</b></li>\n",
        "    <li>BestScore: Score of the comment, likely used by the site to help determine the order comments appear in -> <b>Not used</b></li>\n",
        "</ul>\n",
        "\n",
        "<ul>\n",
        "<li>UserReputation: Internal score of the site, roughly quantifying the past behavior of the user </li>\n",
        "<li>ReplyCount: Number of replies to the comment</li>\n",
        "<li>ThumbsUpCount: Number of up-votes the comment has received</li>\n",
        "<li>ThumbsDownCount: Number of down-votes the comment has received</li>\n",
        "    <li>Recipe_Review: Text content of the comment</li>\n",
        "    </ul>\n",
        "    \n",
        "* Rating: The score on a 1 to 5 scale that the user gave to the recipe. A score of 0 means that no score was given (Target Variable)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-07T18:48:54.736429Z",
          "iopub.status.busy": "2024-04-07T18:48:54.736059Z",
          "iopub.status.idle": "2024-04-07T18:48:56.685276Z",
          "shell.execute_reply": "2024-04-07T18:48:56.6842Z",
          "shell.execute_reply.started": "2024-04-07T18:48:54.736398Z"
        },
        "id": "J4TQ4snLshAC",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "from sklearn.compose import make_column_transformer\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler, FunctionTransformer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "\n",
        "from sklearn.feature_selection import SequentialFeatureSelector,mutual_info_classif,RFE,SelectKBest\n",
        "from sklearn.model_selection import cross_val_score,RandomizedSearchCV,GridSearchCV\n",
        "\n",
        "from scipy.stats import uniform, randint\n",
        "\n",
        "import pickle\n",
        "\n",
        "rs=42"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-07T18:48:56.687628Z",
          "iopub.status.busy": "2024-04-07T18:48:56.686982Z",
          "iopub.status.idle": "2024-04-07T18:48:56.695339Z",
          "shell.execute_reply": "2024-04-07T18:48:56.694152Z",
          "shell.execute_reply.started": "2024-04-07T18:48:56.687593Z"
        },
        "id": "9zYpuc9AJEBO",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "UserReputation_preprocess=make_pipeline(StandardScaler())\n",
        "ReplyCount_preprocess=make_pipeline(StandardScaler())\n",
        "ThumbsUpCount_preprocess=make_pipeline(StandardScaler())\n",
        "ThumbsDownCount_preprocess=make_pipeline(StandardScaler())\n",
        "\n",
        "# Using the TfidfVectorizer only for the purposes of 'Splitting' that is separating sentences into words, 'frequency counting', 'tf*idf' and finally 'normalization'\n",
        "# Manual lemmatization, lowercase conversion,accent stripping, stop word removal has been done via replace_patterns() as stop word removal and identification of tfidf is pathetic in sklearn!\n",
        "# Another reason is for optimization! Only the above(1st comment) procedures are dynamic that is \"need to be repeated in a cv loop\"\n",
        "# 2nd comment procedures remain common be it any split of a cv loop!\n",
        "\n",
        "# NEVER APPLY TRANSFORMERS PERTAINING TO THE SAME COLUMN IN TWO DIFFERENT ITERATIONS!!!! ex: Applying below functiontransformer in one row and then custom transformer in the next even though both pertain to the same column 'Recipe_Reviews'\n",
        "# Go with custom transformer whenever you are adding new columns, cos function_transformer's get_feature_names_out causes problems otherwise\n",
        "\n",
        "preprocess = make_column_transformer(\n",
        "    (UserReputation_preprocess, ['UserReputation']),\n",
        "    (ReplyCount_preprocess, ['ReplyCount']),\n",
        "    (ThumbsUpCount_preprocess, ['ThumbsUpCount']),\n",
        "    (ThumbsDownCount_preprocess, ['ThumbsDownCount']),\n",
        "    # (make_pipeline(FunctionTransformer(replace_patterns, feature_names_out='one-to-one'),TfidfTransformer()), ['Recipe_Review']),\n",
        "    (TfidfTransformer(),['Recipe_Review']),\n",
        "    remainder='drop',\n",
        "    n_jobs=-1,\n",
        "    verbose_feature_names_out=False,\n",
        "    sparse_threshold=0,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-07T18:48:56.698189Z",
          "iopub.status.busy": "2024-04-07T18:48:56.69741Z",
          "iopub.status.idle": "2024-04-07T18:49:00.328024Z",
          "shell.execute_reply": "2024-04-07T18:49:00.327087Z",
          "shell.execute_reply.started": "2024-04-07T18:48:56.698139Z"
        },
        "id": "_lxBYpPgUYG1",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "temp=pd.DataFrame(preprocess.fit_transform(X2),columns=preprocess.get_feature_names_out())\n",
        "temp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IJLLIvMmzm-8"
      },
      "source": [
        "# Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-05T04:19:07.6877Z",
          "iopub.status.busy": "2024-04-05T04:19:07.687277Z",
          "iopub.status.idle": "2024-04-05T04:19:07.701379Z",
          "shell.execute_reply": "2024-04-05T04:19:07.700478Z",
          "shell.execute_reply.started": "2024-04-05T04:19:07.687667Z"
        },
        "id": "ZixNd--Hz-Su",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "with open('logreg_clf.pkl', 'wb') as file:\n",
        "    pickle.dump(lg_clf, file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-07T18:50:06.122236Z",
          "iopub.status.busy": "2024-04-07T18:50:06.121136Z",
          "iopub.status.idle": "2024-04-07T18:50:06.136044Z",
          "shell.execute_reply": "2024-04-07T18:50:06.135245Z",
          "shell.execute_reply.started": "2024-04-07T18:50:06.122163Z"
        },
        "id": "yZYZK5716Ag6",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "with open('../input/dataset/logreg_clf.pkl', 'rb') as file:\n",
        "    clf = pickle.load(file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "2BJSLBf86zuM",
        "outputId": "55a26627-894e-4c10-d426-c17a7ce8aa77"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_acb28066-4483-4a83-b2d4-701711f87955\", \"lg_clf.pkl\", 143792)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from google.colab import files\n",
        "from google.colab import drive\n",
        "\n",
        "with open('lg_clf.pkl', 'wb') as file:\n",
        "    pickle.dump(lg_clf, file)\n",
        "\n",
        "try:\n",
        "    files.download('lg_clf.pkl')\n",
        "except:\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "    !cp lg_clf.pkl /content/drive/MyDrive/\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TEEY5rg2zB5-"
      },
      "source": [
        "## KNeighborsClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-05T04:18:46.10164Z",
          "iopub.status.busy": "2024-04-05T04:18:46.101208Z",
          "iopub.status.idle": "2024-04-05T04:18:46.110166Z",
          "shell.execute_reply": "2024-04-05T04:18:46.109059Z",
          "shell.execute_reply.started": "2024-04-05T04:18:46.101603Z"
        },
        "id": "ZCEj5K1CvnHE",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "param_grid = {\n",
        "    'kneighborsclassifier__n_neighbors': range(5,106,10),\n",
        "    'kneighborsclassifier__weights': ['uniform'],\n",
        "    'selectkbest__k': [20,30,40],\n",
        "}\n",
        "\n",
        "knc_clf= GridSearchCV(make_pipeline(\n",
        "    preprocess,\n",
        "    SelectKBest(mutual_info_classif),\n",
        "    KNeighborsClassifier(),\n",
        "    ),\n",
        "                              param_grid,\n",
        "                              scoring='accuracy',\n",
        "                              cv=10,\n",
        "                              n_jobs=-1,\n",
        "                              refit=True,\n",
        "                              verbose=4,\n",
        "                              error_score=-1,\n",
        "                              return_train_score=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "12-V7n_n0Jj6"
      },
      "outputs": [],
      "source": [
        "knc_clf.fit(X1,y1)\n",
        "print(\"Best parameters: \", knc_clf.best_params_)\n",
        "print(\"Best score: \", knc_clf.best_score_)\n",
        "print(\"Mean test scores: \", knc_clf.cv_results_['mean_test_score'])\n",
        "print(\"Results: \",knc_clf.cv_results_)\n",
        "\n",
        "# weights: distance giving >0.9 on entire train while unifrom gives 0.76 on both\n",
        "# 'distance' did overfit the data with 0.75 test score... best estimator gave test score of 0.7619"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zyV9yePVWDlJ"
      },
      "source": [
        "## Logistic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "LSiPMA5qWGuc"
      },
      "outputs": [],
      "source": [
        "param_grid = [\n",
        "    # {\n",
        "    # 'logisticregression__C': [1], #f 0.76455927\n",
        "    # 'logisticregression__max_iter': [10000], #f\n",
        "    # 'logisticregression__penalty': ['l2'], #f\n",
        "    # 'logisticregression__solver': ['newton-cholesky'], #f\n",
        "    # 'logisticregression__class_weight': [None], #f\n",
        "    # 'logisticregression__tol': [1e-3], #f\n",
        "    # 'logisticregression__warm_start': [True], #f\n",
        "    # },\n",
        "    # {\n",
        "    # 'logisticregression__C':[0.1,1,10],\n",
        "    # 'logisticregression__penalty': ['elasticnet'],\n",
        "    # 'logisticregression__solver': ['saga'],\n",
        "    # 'logisticregression__class_weight': [None,'balanced'],\n",
        "    # 'logisticregression__warm_start': [True,False],\n",
        "    # 'logisticregression__tol': [1e-4],\n",
        "    # 'logisticregression__l1_ratio': [0.5], #0.7645593735211135\n",
        "    # # Best parameters:  {'logisticregression__l1_ratio': 0.5, 'logisticregression__penalty': 'elasticnet', 'logisticregression__solver': 'saga', 'logisticregression__tol': 0.0001}\n",
        "    # },\n",
        "    # {\n",
        "    # 'logisticregression__C':[0.1,1,10],\n",
        "\n",
        "    # 'logisticregression__penalty': ['l1'], #0.76455929\n",
        "    # 'logisticregression__solver': ['liblinear'],\n",
        "    # },\n",
        "    {\n",
        "        'rfe__n_features_to_select':[10,20,30],\n",
        "    }\n",
        "              ]\n",
        "\n",
        "LogReg=LogisticRegression(multi_class='auto',\n",
        "                          random_state=rs,\n",
        "                          verbose=1,\n",
        "                          n_jobs=-1,\n",
        "                          dual=False,\n",
        "                          fit_intercept=True,\n",
        "\n",
        "                          max_iter=10000,\n",
        "                          class_weight=None,\n",
        "                          solver='newton-cholesky',\n",
        "                          warm_start=True,\n",
        "                          l1_ratio=None,\n",
        "                          penalty='l2',\n",
        "                          tol=1e-3,\n",
        "                          C=1,\n",
        "                          intercept_scaling=1,\n",
        "                           )\n",
        "\n",
        "lg_clf = GridSearchCV(\n",
        "    make_pipeline(\n",
        "        preprocess,\n",
        "        RFE(LogisticRegression(),\n",
        "              verbose=1,\n",
        "\n",
        "              n_features_to_select=20,\n",
        "              step=1,\n",
        "              ),\n",
        "        # LogReg\n",
        "        ),\n",
        "\n",
        "    param_grid,\n",
        "    scoring='accuracy',\n",
        "    cv=5,\n",
        "    n_jobs=-1,\n",
        "    refit=True,\n",
        "    verbose=4,\n",
        "    error_score='raise',\n",
        "    return_train_score=True,\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JeNFbc28dZD6"
      },
      "outputs": [],
      "source": [
        "lg_clf.best_estimator_.named_steps['logisticregression'].coef_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JOolBixNdVq-",
        "outputId": "83cd6506-9156-4e85-d7b2-4705e96ffebf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n"
          ]
        }
      ],
      "source": [
        "lg_clf.fit(X1,y1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "ZHn0Hk0rWO0w",
        "outputId": "f6338225-287d-462b-d878-89c4eddb2241"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-8d01fff0433f>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlg_clf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Best parameters: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlg_clf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Best score: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlg_clf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Mean test scores: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlg_clf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv_results_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mean_test_score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Mean train scores: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlg_clf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv_results_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mean_train_score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    872\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 874\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    875\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1386\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1387\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1388\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    819\u001b[0m                     )\n\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 821\u001b[0;31m                 out = parallel(\n\u001b[0m\u001b[1;32m    822\u001b[0m                     delayed(_fit_and_score)(\n\u001b[1;32m    823\u001b[0m                         \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_estimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         )\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1950\u001b[0m         \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1952\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_generator\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1953\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1954\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1593\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1594\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1595\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_retrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1596\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1597\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mGeneratorExit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1705\u001b[0m                 (self._jobs[0].get_status(\n\u001b[1;32m   1706\u001b[0m                     timeout=self.timeout) == TASK_PENDING)):\n\u001b[0;32m-> 1707\u001b[0;31m                 \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1708\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "lg_clf.fit(X1,y1)\n",
        "print(\"Best parameters: \", lg_clf.best_params_)\n",
        "print(\"Best score: \", lg_clf.best_score_)\n",
        "print(\"Mean test scores: \", lg_clf.cv_results_['mean_test_score'])\n",
        "print(\"Mean train scores: \", lg_clf.cv_results_['mean_train_score'])\n",
        "print(\"Results: \",lg_clf.cv_results_)\n",
        "\n",
        "# balanced gives pathetic results\n",
        "# C = 1 seems to be the way\n",
        "# newton and lbfgs same results but lbfgs faster\n",
        "# cholesky seems to perform better"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vNCbnEQPfvQ5"
      },
      "source": [
        "## SVC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6xXgQ6GAfxwg"
      },
      "outputs": [],
      "source": [
        "param_grid = {\n",
        "    'svc__C': [10], #f\n",
        "    'svc__kernel': ['linear'], #f\n",
        "    'svc__gamma': ['scale'], #f\n",
        "    'svc__tol': [1e-3], #f\n",
        "    'svc__max_iter': [10000] #f\n",
        "}\n",
        "svc=SVC()\n",
        "\n",
        "svc_clf = GridSearchCV(\n",
        "    make_pipeline(\n",
        "        preprocess,\n",
        "        svc,\n",
        "        ),\n",
        "\n",
        "    param_grid,\n",
        "    scoring='accuracy',\n",
        "    cv=5,\n",
        "    n_jobs=-1,\n",
        "    refit=True,\n",
        "    verbose=4,\n",
        "    error_score='raise',\n",
        "    return_train_score=True,\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q4nSYoA3gHkc",
        "outputId": "2d19c5bc-d1fc-4d29-f0ba-52789fa1d928"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
            "Best parameters:  {'svc__C': 10, 'svc__gamma': 'scale', 'svc__kernel': 'linear', 'svc__max_iter': 10000, 'svc__tol': 0.001}\n",
            "Best score:  0.762505619600845\n",
            "Mean test scores:  [0.76191892 0.76184563 0.76250562]\n",
            "Mean train scores:  [0.76219379 0.76289058 0.76358736]\n",
            "Results:  {'mean_fit_time': array([ 6.6865099 ,  7.27550526, 10.32608929]), 'std_fit_time': array([0.30229687, 0.44329414, 1.42169643]), 'mean_score_time': array([0.87075114, 0.8878777 , 1.11216073]), 'std_score_time': array([0.03343352, 0.0228726 , 0.03939511]), 'param_svc__C': masked_array(data=[0.1, 1, 10],\n",
            "             mask=[False, False, False],\n",
            "       fill_value='?',\n",
            "            dtype=object), 'param_svc__gamma': masked_array(data=['scale', 'scale', 'scale'],\n",
            "             mask=[False, False, False],\n",
            "       fill_value='?',\n",
            "            dtype=object), 'param_svc__kernel': masked_array(data=['linear', 'linear', 'linear'],\n",
            "             mask=[False, False, False],\n",
            "       fill_value='?',\n",
            "            dtype=object), 'param_svc__max_iter': masked_array(data=[10000, 10000, 10000],\n",
            "             mask=[False, False, False],\n",
            "       fill_value='?',\n",
            "            dtype=object), 'param_svc__tol': masked_array(data=[0.001, 0.001, 0.001],\n",
            "             mask=[False, False, False],\n",
            "       fill_value='?',\n",
            "            dtype=object), 'params': [{'svc__C': 0.1, 'svc__gamma': 'scale', 'svc__kernel': 'linear', 'svc__max_iter': 10000, 'svc__tol': 0.001}, {'svc__C': 1, 'svc__gamma': 'scale', 'svc__kernel': 'linear', 'svc__max_iter': 10000, 'svc__tol': 0.001}, {'svc__C': 10, 'svc__gamma': 'scale', 'svc__kernel': 'linear', 'svc__max_iter': 10000, 'svc__tol': 0.001}], 'split0_test_score': array([0.76054272, 0.75980931, 0.76054272]), 'split1_test_score': array([0.76237624, 0.76237624, 0.76200953]), 'split2_test_score': array([0.76054272, 0.76090942, 0.76274294]), 'split3_test_score': array([0.76164283, 0.76090942, 0.76310964]), 'split4_test_score': array([0.7644901 , 0.76522377, 0.76412326]), 'mean_test_score': array([0.76191892, 0.76184563, 0.76250562]), 'std_test_score': array([0.00146179, 0.00187579, 0.00119474]), 'rank_test_score': array([2, 3, 1], dtype=int32), 'split0_train_score': array([0.76217108, 0.76345466, 0.76446319]), 'split1_train_score': array([0.76235445, 0.7626295 , 0.76317961]), 'split2_train_score': array([0.76198771, 0.76235445, 0.76427982]), 'split3_train_score': array([0.76272119, 0.76354635, 0.76244614]), 'split4_train_score': array([0.76173451, 0.76246791, 0.76356802]), 'mean_train_score': array([0.76219379, 0.76289058, 0.76358736]), 'std_train_score': array([0.00033403, 0.00050645, 0.00073697])}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "svc_clf.fit(X1,y1)\n",
        "print(\"Best parameters: \", svc_clf.best_params_)\n",
        "print(\"Best score: \", svc_clf.best_score_)\n",
        "print(\"Mean test scores: \", svc_clf.cv_results_['mean_test_score'])\n",
        "print(\"Mean train scores: \", svc_clf.cv_results_['mean_train_score'])\n",
        "print(\"Results: \",svc_clf.cv_results_)\n",
        "\n",
        "#rbf overfitting... linear can't cross 0.7625 but doens't overfit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2kGnRjV5JEBO"
      },
      "source": [
        "# Submit File Generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 227
        },
        "execution": {
          "iopub.execute_input": "2024-04-05T04:50:14.628518Z",
          "iopub.status.busy": "2024-04-05T04:50:14.627365Z",
          "iopub.status.idle": "2024-04-05T04:50:14.705741Z",
          "shell.execute_reply": "2024-04-05T04:50:14.704727Z",
          "shell.execute_reply.started": "2024-04-05T04:50:14.628463Z"
        },
        "id": "3XVc9JSKn_ub",
        "outputId": "82d0f0df-3e08-4064-b5f8-42c320f31661",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;columntransformer&#x27;,\n",
              "                 ColumnTransformer(n_jobs=-1, sparse_threshold=0,\n",
              "                                   transformers=[(&#x27;pipeline-1&#x27;,\n",
              "                                                  Pipeline(steps=[(&#x27;standardscaler&#x27;,\n",
              "                                                                   StandardScaler())]),\n",
              "                                                  [&#x27;UserReputation&#x27;]),\n",
              "                                                 (&#x27;pipeline-2&#x27;,\n",
              "                                                  Pipeline(steps=[(&#x27;standardscaler&#x27;,\n",
              "                                                                   StandardScaler())]),\n",
              "                                                  [&#x27;ReplyCount&#x27;]),\n",
              "                                                 (&#x27;pipeline-3&#x27;,\n",
              "                                                  Pipeline(steps=[(&#x27;standardscaler&#x27;,\n",
              "                                                                   StandardScaler())]),\n",
              "                                                  [&#x27;ThumbsUpCount&#x27;]),\n",
              "                                                 (&#x27;pipeline-4&#x27;,\n",
              "                                                  Pipeline(steps=[(&#x27;standardscaler&#x27;,\n",
              "                                                                   StandardScaler())]),\n",
              "                                                  [&#x27;ThumbsDownCount&#x27;]),\n",
              "                                                 (&#x27;tfidftransformer&#x27;,\n",
              "                                                  TfidfTransformer(),\n",
              "                                                  [&#x27;Recipe_Review&#x27;])],\n",
              "                                   verbose_feature_names_out=False)),\n",
              "                (&#x27;selectkbest&#x27;,\n",
              "                 SelectKBest(k=40,\n",
              "                             score_func=&lt;function mutual_info_classif at 0x7e57339c5090&gt;)),\n",
              "                (&#x27;kneighborsclassifier&#x27;, KNeighborsClassifier(n_neighbors=25))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;columntransformer&#x27;,\n",
              "                 ColumnTransformer(n_jobs=-1, sparse_threshold=0,\n",
              "                                   transformers=[(&#x27;pipeline-1&#x27;,\n",
              "                                                  Pipeline(steps=[(&#x27;standardscaler&#x27;,\n",
              "                                                                   StandardScaler())]),\n",
              "                                                  [&#x27;UserReputation&#x27;]),\n",
              "                                                 (&#x27;pipeline-2&#x27;,\n",
              "                                                  Pipeline(steps=[(&#x27;standardscaler&#x27;,\n",
              "                                                                   StandardScaler())]),\n",
              "                                                  [&#x27;ReplyCount&#x27;]),\n",
              "                                                 (&#x27;pipeline-3&#x27;,\n",
              "                                                  Pipeline(steps=[(&#x27;standardscaler&#x27;,\n",
              "                                                                   StandardScaler())]),\n",
              "                                                  [&#x27;ThumbsUpCount&#x27;]),\n",
              "                                                 (&#x27;pipeline-4&#x27;,\n",
              "                                                  Pipeline(steps=[(&#x27;standardscaler&#x27;,\n",
              "                                                                   StandardScaler())]),\n",
              "                                                  [&#x27;ThumbsDownCount&#x27;]),\n",
              "                                                 (&#x27;tfidftransformer&#x27;,\n",
              "                                                  TfidfTransformer(),\n",
              "                                                  [&#x27;Recipe_Review&#x27;])],\n",
              "                                   verbose_feature_names_out=False)),\n",
              "                (&#x27;selectkbest&#x27;,\n",
              "                 SelectKBest(k=40,\n",
              "                             score_func=&lt;function mutual_info_classif at 0x7e57339c5090&gt;)),\n",
              "                (&#x27;kneighborsclassifier&#x27;, KNeighborsClassifier(n_neighbors=25))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">columntransformer: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(n_jobs=-1, sparse_threshold=0,\n",
              "                  transformers=[(&#x27;pipeline-1&#x27;,\n",
              "                                 Pipeline(steps=[(&#x27;standardscaler&#x27;,\n",
              "                                                  StandardScaler())]),\n",
              "                                 [&#x27;UserReputation&#x27;]),\n",
              "                                (&#x27;pipeline-2&#x27;,\n",
              "                                 Pipeline(steps=[(&#x27;standardscaler&#x27;,\n",
              "                                                  StandardScaler())]),\n",
              "                                 [&#x27;ReplyCount&#x27;]),\n",
              "                                (&#x27;pipeline-3&#x27;,\n",
              "                                 Pipeline(steps=[(&#x27;standardscaler&#x27;,\n",
              "                                                  StandardScaler())]),\n",
              "                                 [&#x27;ThumbsUpCount&#x27;]),\n",
              "                                (&#x27;pipeline-4&#x27;,\n",
              "                                 Pipeline(steps=[(&#x27;standardscaler&#x27;,\n",
              "                                                  StandardScaler())]),\n",
              "                                 [&#x27;ThumbsDownCount&#x27;]),\n",
              "                                (&#x27;tfidftransformer&#x27;, TfidfTransformer(),\n",
              "                                 [&#x27;Recipe_Review&#x27;])],\n",
              "                  verbose_feature_names_out=False)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">pipeline-1</label><div class=\"sk-toggleable__content\"><pre>[&#x27;UserReputation&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">pipeline-2</label><div class=\"sk-toggleable__content\"><pre>[&#x27;ReplyCount&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">pipeline-3</label><div class=\"sk-toggleable__content\"><pre>[&#x27;ThumbsUpCount&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">pipeline-4</label><div class=\"sk-toggleable__content\"><pre>[&#x27;ThumbsDownCount&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">tfidftransformer</label><div class=\"sk-toggleable__content\"><pre>[&#x27;Recipe_Review&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfTransformer</label><div class=\"sk-toggleable__content\"><pre>TfidfTransformer()</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SelectKBest</label><div class=\"sk-toggleable__content\"><pre>SelectKBest(k=40, score_func=&lt;function mutual_info_classif at 0x7e57339c5090&gt;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier(n_neighbors=25)</pre></div></div></div></div></div></div></div>"
            ],
            "text/plain": [
              "Pipeline(steps=[('columntransformer',\n",
              "                 ColumnTransformer(n_jobs=-1, sparse_threshold=0,\n",
              "                                   transformers=[('pipeline-1',\n",
              "                                                  Pipeline(steps=[('standardscaler',\n",
              "                                                                   StandardScaler())]),\n",
              "                                                  ['UserReputation']),\n",
              "                                                 ('pipeline-2',\n",
              "                                                  Pipeline(steps=[('standardscaler',\n",
              "                                                                   StandardScaler())]),\n",
              "                                                  ['ReplyCount']),\n",
              "                                                 ('pipeline-3',\n",
              "                                                  Pipeline(steps=[('standardscaler',\n",
              "                                                                   StandardScaler())]),\n",
              "                                                  ['ThumbsUpCount']),\n",
              "                                                 ('pipeline-4',\n",
              "                                                  Pipeline(steps=[('standardscaler',\n",
              "                                                                   StandardScaler())]),\n",
              "                                                  ['ThumbsDownCount']),\n",
              "                                                 ('tfidftransformer',\n",
              "                                                  TfidfTransformer(),\n",
              "                                                  ['Recipe_Review'])],\n",
              "                                   verbose_feature_names_out=False)),\n",
              "                ('selectkbest',\n",
              "                 SelectKBest(k=40,\n",
              "                             score_func=<function mutual_info_classif at 0x7e57339c5090>)),\n",
              "                ('kneighborsclassifier', KNeighborsClassifier(n_neighbors=25))])"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "clf.best_estimator_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-07T18:50:25.543228Z",
          "iopub.status.busy": "2024-04-07T18:50:25.54282Z",
          "iopub.status.idle": "2024-04-07T18:50:30.02799Z",
          "shell.execute_reply": "2024-04-07T18:50:30.026572Z",
          "shell.execute_reply.started": "2024-04-07T18:50:25.543171Z"
        },
        "id": "YOGPD0blvJpv",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Preprocess the test data\n",
        "X1_test = X_test.copy(deep=True)\n",
        "X1_test['Recipe_Review'] = replace_patterns(X_test['Recipe_Review'])\n",
        "\n",
        "# When you call clf.predict(X1_test), it will apply only the transform methods of the pipeline components to the preprocessed test data X1_test. It will not call the fit methods again.\n",
        "#The estimator pipeline has already been trained on the entire X_train by gridsearch\n",
        "# best_estimator_ basically contains the entire pipeline which you passed to Gridsearchcv fitted on the entire X you passed it\n",
        "\n",
        "predictions = clf.best_estimator_.predict(X1_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-07T18:50:34.202814Z",
          "iopub.status.busy": "2024-04-07T18:50:34.201803Z",
          "iopub.status.idle": "2024-04-07T18:50:34.22296Z",
          "shell.execute_reply": "2024-04-07T18:50:34.221818Z",
          "shell.execute_reply.started": "2024-04-07T18:50:34.202776Z"
        },
        "id": "-NRGmgn8JEBO",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Save test predictions to file\n",
        "output = pd.DataFrame({'Rating': predictions},index=range(1,4547))\n",
        "output.to_csv('submission.csv', index_label=\"ID\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W936vmhtc4kf"
      },
      "outputs": [],
      "source": [
        "# with open('text.csv', 'w') as file:\n",
        "#     X2.Recipe_Review.to_csv(file, index=False, header=False)\n",
        "# with open('X1.csv', 'w') as file:\n",
        "    # X1.to_csv(file, index=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "ppv7cNoZJEBJ",
        "ZzuP1tsrTHlG"
      ],
      "provenance": []
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "databundleVersionId": 7452256,
          "sourceId": 67079,
          "sourceType": "competition"
        },
        {
          "datasetId": 4748833,
          "sourceId": 8056944,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 30635,
      "isGpuEnabled": false,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
